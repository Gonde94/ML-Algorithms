{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training an LLM\n",
    "\n",
    "1. Iterate over training epochs (one epoch is a complete pass over a training set).\n",
    "2. Iterate over batches in each training epoch (# of batches = training set size / size of each batch).\n",
    "3. Reset loss gradients from previous batch iteration.\n",
    "4. Calculate loss on current batch.\n",
    "5. Backward pass to calculate loss gradients. \n",
    "6. Update model weights using loss gradients. \n",
    "7. Print training and validation set losses.\n",
    "8. Generate sample text for visual inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from Chapter04 import GPTModel, create_dataloader_v1, generate_text_simple\n",
    "from Chapter05 import calc_loss_batch, calc_loss_loader, text_to_token_ids, token_ids_to_text, tokeniser\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50_257,\n",
    "    \"context_length\": 256, # shortened from 1,024\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader,\n",
    "                       optimiser, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokeniser):\n",
    "    \n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs): # step 1\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader: # step 2\n",
    "            optimiser.zero_grad() # step 3\n",
    "            loss = calc_loss_batch( # step 4\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            loss.backward() # step 5\n",
    "            optimiser.step() # step 6\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0: # step 7\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Epoch {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, \"\n",
    "                      f\"Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "\n",
    "        generate_and_print_sample( # step 8\n",
    "            model, tokeniser, device, start_context\n",
    "        )\n",
    "    return train_losses, val_losses, track_tokens_seen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval() # dropout is disabled for stable, reproducible results\n",
    "    with torch.no_grad(): # disables gradient tracking\n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(\n",
    "            val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokeniser).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, \n",
    "            idx=encoded,\n",
    "            max_new_tokens=50,\n",
    "            context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokeniser)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
