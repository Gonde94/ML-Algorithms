{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix path to be able to import classes\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the src folder to the Python path\n",
    "src_path = Path(\"../src\").resolve()  # Adjust the relative path based on where your notebook is\n",
    "sys.path.append(str(src_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><u>Exercise 3.1</u></b>: Comparing SelfAttention_v1 and SelfAttention_v2.\n",
    "\n",
    "nn.Linear in SelfAttention_v2 uses a different weight initialisation scheme as nn.Parameter(torch.rand(d_in, d_out)) used in SelfAttention_v1, which causes the mechanisms to produce different results. To check that both implementations are otherwise similar, we can transfer the weight matrices from object v2 to v1, such that both objects then produce the same results. \n",
    "\n",
    "Correctly assign the weights from an instance of SelfAttention_v2 to SelfAttention_v1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3751, 0.8610],\n",
      "        [1.4201, 0.8892],\n",
      "        [1.4198, 0.8890],\n",
      "        [1.3533, 0.8476],\n",
      "        [1.3746, 0.8606],\n",
      "        [1.3620, 0.8532]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from Chapter03 import SelfAttention_v1, SelfAttention_v2, inputs, d_in, d_out\n",
    "\n",
    "torch.manual_seed(42)\n",
    "sa_v1 = SelfAttention_v1(d_in, d_out)\n",
    "print(sa_v1(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3755, 0.2777],\n",
      "        [0.3761, 0.2831],\n",
      "        [0.3761, 0.2833],\n",
      "        [0.3768, 0.2763],\n",
      "        [0.3754, 0.2836],\n",
      "        [0.3772, 0.2746]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "sa_v2 = SelfAttention_v2(d_in, d_out)\n",
    "print(sa_v2(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1 class weight: Parameter containing:\n",
      "tensor([[0.2566, 0.7936],\n",
      "        [0.9408, 0.1332],\n",
      "        [0.9346, 0.5936]], requires_grad=True)\n",
      "\n",
      "V2 class weight: Parameter containing:\n",
      "tensor([[-0.2811,  0.3391,  0.5090],\n",
      "        [-0.4236,  0.5018,  0.1081]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"V1 class weight:\", sa_v1.W_key)\n",
    "print(\"\\nV2 class weight:\", sa_v2.W_key.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V2 class weight transposed:\n",
      " tensor([[-0.2811, -0.4236],\n",
      "        [ 0.3391,  0.5018],\n",
      "        [ 0.5090,  0.1081]], grad_fn=<PermuteBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"V2 class weight transposed:\\n\", sa_v2.W_key.weight.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_v1.W_key = torch.nn.Parameter(sa_v2.W_key.weight.T)\n",
    "sa_v1.W_query = torch.nn.Parameter(sa_v2.W_query.weight.T)\n",
    "sa_v1.W_value = torch.nn.Parameter(sa_v2.W_value.weight.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3755, 0.2777],\n",
      "        [0.3761, 0.2831],\n",
      "        [0.3761, 0.2833],\n",
      "        [0.3768, 0.2763],\n",
      "        [0.3754, 0.2836],\n",
      "        [0.3772, 0.2746]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "print(sa_v1(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensors are equal: True\n"
     ]
    }
   ],
   "source": [
    "equal = torch.equal(sa_v1(inputs), sa_v2(inputs))\n",
    "print(\"Tensors are equal:\", equal) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
