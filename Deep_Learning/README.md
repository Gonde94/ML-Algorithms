## Deep Learning

The goal is to develop my understanding of Deep Learning through reading books and blogs, following tutorials, and eventually working on my own practical projects. I'll list some resources of interest here, though I won't be able to work through all of them.

<u><b>General</b></u>
- "Inside Deep Learning" by Edward Raff (purchased the book)
- "Understanding Deep Learning" by Simon Prince (purchased the book)
- Distil have some very good posts. This is one on momentum: https://distill.pub/2017/momentum/
- Colah also has a good blog: https://colah.github.io/posts/2014-07-NLP-RNNs-Representations/
- Tutorial on replicating a paper: https://www.learnpytorch.io/08_pytorch_paper_replicating/ 

<u><b>LLM-specific</b></u>
- "Build a Large Language Model from Scratch" by Sebastian Rascka (working through the book)
- Karpathy's neural network zero to hero playlist: https://www.youtube.com/watch?v=VMj-3S1tku0&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ. I think there's a lot of overlap between this and Raschka's book, but Karpathy's videos are more interactive and go into greater detail.
- Lilian Weng's blog, specifically the articles on Transformers and attention: https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/. 
- Eugene Yan has a blog on various topics. The LLM stuff appear to be more on the MLOps side: https://eugeneyan.com/
- LLM visualisation: https://bbycroft.net/llm 

<u><b>Image generation</b></u>
- Hugging face tutorial series: https://huggingface.co/docs/diffusers/tutorials/tutorial_overview